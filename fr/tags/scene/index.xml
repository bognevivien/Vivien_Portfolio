<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scene on Vivien BOGNE</title>
    <link>https://vivien-dsa.github.io/Vivien_Portfolio/fr/tags/scene/</link>
    <description>Recent content in scene on Vivien BOGNE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Feb 2021 10:58:08 -0400</lastBuildDate><atom:link href="https://vivien-dsa.github.io/Vivien_Portfolio/fr/tags/scene/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title> AWS cloud computing (EMR Cluster, spark application ) </title>
      <link>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-4/</link>
      <pubDate>Tue, 09 Feb 2021 10:58:08 -0400</pubDate>
      
      <guid>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-4/</guid>
      <description>Après avoir créer l&amp;rsquo;application de comptage de mot nous avons créer un corpus de 20 GB de mot en utilisant nltk. Ensuite nous avons crée un cluster EMR, chargé les données sur S3 et finalement définit une application SPARK dans notre cluster.  Le rapport complet se trouve ici : https://github.com/vivien-DSA/Cloud-computing-using-Pyspark-and-AWS</description>
    </item>
    
    <item>
      <title>Recommender system</title>
      <link>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-3/</link>
      <pubDate>Sat, 09 Jan 2021 10:58:08 -0400</pubDate>
      
      <guid>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-3/</guid>
      <description>Il s&amp;rsquo;agit d&amp;rsquo;utiliser le jeux de données MovieLens dataset afin de créer un système de recommendation. Nous créons un pipeline qui comprends : : Le chargement des données, la préparation des données, l&amp;rsquo;entrainement de modeles, une validation croisée et l&amp;rsquo;évaluation du modèles. Après avoir utilisé les modèles SVM, KNN: basé sur les utilisateurs et basé sur les éléments, nous effection un benchmarking. Il en ressort que le meilleur modèle est KNN: item based using the cosine bien que celui çi possède un temps d&amp;rsquo;entrainement beaucoup plus grand.</description>
    </item>
    
    <item>
      <title> Neural Machine Translation using openNMT</title>
      <link>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-1/</link>
      <pubDate>Wed, 09 Dec 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-1/</guid>
      <description>Nous utilisons un corpus parallèles et OpenNMT pour entrainer un modèle de traduction automatiques. Nous effectuons les operations ( sub Tokenization, training, Translatation, Detokenization et puis evaluation ). il en ressort un traducteur avec une métrique BLEU Score % de 30, Nous avons utiliser un encodage BPE de taille 32k et comme réseaux de neurones un transformer.  Lien du notebook : https://github.com/vivien-DSA/Create-a-NMT</description>
    </item>
    
    <item>
      <title>Quel est le pays le plus dangereux de l&#39;UE? ( EPITA ) </title>
      <link>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-2/</link>
      <pubDate>Wed, 09 Dec 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vivien-dsa.github.io/Vivien_Portfolio/fr/post/projet-2/</guid>
      <description>Nous utilisons les statistiques de criminalité du site europea.eu pour analyser les pays les plus dangereux de l&amp;rsquo;Union européenne. Nous avons utilisé 4 ensembles de données, le nombre de vol qualifié, homicides intentionnels, vol de voitures et d&amp;rsquo;agressions. Nous avons crée des visuels ( Chloropleth maps, histogrammes et diagrammes) pour invalider l&amp;rsquo;hypothèse.
  Analyse du besoin : Nous utilisons les statistiques de criminalité du site europea.eu pour analyser les pays les plus dangereux de l&amp;rsquo;Union européenne.</description>
    </item>
    
  </channel>
</rss>
